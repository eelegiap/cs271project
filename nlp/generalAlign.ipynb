{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libraries, modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install PyArabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download xx_ent_wiki_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.morphology import Morphology\n",
    "\n",
    "import pyarabic.araby as araby\n",
    "import pyarabic.number as number\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import json\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFY SOURCE LANGUAGE\n",
    "srclang = 'Arabic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install spacy lang models\n",
    "\n",
    "if srclang == 'Spanish':\n",
    "    sourceNLP = spacy.load(\"es_core_news_sm\")\n",
    "elif srclang == 'Russian':\n",
    "    sourceNLP = spacy.load(\"ru_core_news_sm\")\n",
    "elif srclang == 'Arabic':\n",
    "    sourceNLP = spacy.load(\"xx_ent_wiki_sm\")\n",
    "    sourceNLP.add_pipe('sentencizer')\n",
    "    \n",
    "engNLP = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load raw texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'texts/{srclang}/rawsource.txt','r') as f:\n",
    "     sourcetxt = f.read().replace('\\n',' ').replace('\\t','')\n",
    "with open(f'texts/{srclang}/rawtarget.txt','r') as f:\n",
    "     targettxt = f.read().replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if srclang == 'Arabic':\n",
    "    # sourcedoc = araby.sentence_tokenize(sourcetxt)\n",
    "    sourcedoc = sourceNLP(sourcetxt)\n",
    "else:\n",
    "    sourcedoc = sourceNLP(sourcetxt)\n",
    "targetdoc = engNLP(targettxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentenize\n",
    "rawsrcsents = []\n",
    "rawtgtsents = []\n",
    "\n",
    "for sent in sourcedoc.sents:\n",
    "    rawsrcsents.append(sent.text)\n",
    "    \n",
    "newrawsrcsents = []\n",
    "for sent in rawsrcsents:\n",
    "    if sent == '':\n",
    "        continue\n",
    "    partfound = False\n",
    "    for part in ['Part I.','Part II.','Part III.','Part IV.','Part V.']:\n",
    "        if part in sent:\n",
    "            newrawsrcsents.append(part)\n",
    "            newrawsrcsents.append(sent.split(part)[1].strip())\n",
    "            partfound = True\n",
    "    if not partfound:\n",
    "        newrawsrcsents.append(sent)\n",
    "rawsrcsents = newrawsrcsents\n",
    "    \n",
    "        \n",
    "for sent in targetdoc.sents:\n",
    "    rawtgtsents.append(sent.text)\n",
    "\n",
    "newrawtgtsents = []\n",
    "for sent in rawtgtsents:\n",
    "    if sent == '':\n",
    "        continue\n",
    "    partfound = False\n",
    "    for part in ['Part I.','Part II.','Part III.','Part IV.','Part V.']:\n",
    "        if part in sent:\n",
    "            newrawtgtsents.append(part)\n",
    "            newrawtgtsents.append(sent.split(part)[1])\n",
    "            partfound = True\n",
    "    if not partfound:\n",
    "        newrawtgtsents.append(sent)\n",
    "rawtgtsents = newrawtgtsents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write standardized files (one line per sentence) for input to Bleualign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the inputs to bleualign\n",
    "with open(f'texts/{srclang}/sourcetextforbleualign.txt','w') as f:\n",
    "    f.write('\\n'.join(rawsrcsents))\n",
    "with open(f'texts/{srclang}/targettextforbleualign.txt','w') as f:\n",
    "    f.write('\\n'.join(rawtgtsents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized sentences for data output\n",
    "srctokens = []\n",
    "if srclang == 'Arabic':\n",
    "    for srcsent in rawsrcsents:\n",
    "        tokens = araby.tokenize(srcsent)\n",
    "        srctokens.append([{'text' : t, 'lemma' : t} for t in tokens])\n",
    "else:\n",
    "    for srcsent in rawsrcsents:\n",
    "        tokens = sourceNLP(srcsent)\n",
    "        srctokens.append([{'text' : t.text, 'lemma' : t.lemma_} for t in tokens])\n",
    "tgttokens = []\n",
    "for tgtsent in rawtgtsents:\n",
    "    tokens = engNLP(tgtsent)\n",
    "    tgttokens.append([{'text' : t.text, 'lemma' : t.lemma_} for t in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Bleualign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install translators --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import translators as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/164 sents translated.\n",
      "machine translation took 2.1140940189361572 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "translatedsourcesents = []\n",
    "for i, sent in enumerate(rawsrcsents[:3]):\n",
    "    if i % 25 == 0:\n",
    "        print(f'{i}/{len(rawsrcsents)} sents translated.')\n",
    "    try:\n",
    "        translatedsourcesents.append(ts.google(sent, to_language = 'en'))\n",
    "    except:\n",
    "        print('problem on',sent)\n",
    "        translatedsourcesents.append('\\n')\n",
    "end = time.time()\n",
    "print(f'machine translation took {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Part I.',\n",
       " 'For this day name, and can not put it where God put him from the month and Sunnis, but can not mention this day a particular time, but almost nearly.',\n",
       " 'The biggest thought that this time was happening today in dawn or lover.']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translatedsourcesents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "if srclang not in ['Arabic','Russian']:\n",
    "    with open(f'texts/{srclang}/translatedsource.txt','w') as f:\n",
    "        f.write('\\n'.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in article 0: \n",
      "processing\n",
      "computing alignment between srctotarget (file 0) and target text\n",
      "Evaluating sentences with bleu\n",
      "finished\n",
      "searching for longest path of good alignments\n",
      "finished\n",
      "Fri Apr 15 10:18:45 2022\n",
      "filling gaps\n",
      "finished\n",
      "Fri Apr 15 10:18:45 2022\n",
      "Results of BLEU 1-to-1 alignment\n",
      "\u001b[92m0: 0\u001b[1;m\n",
      "\u001b[92m1: 1\u001b[1;m\n",
      "\u001b[92m2: 2\u001b[1;m\n",
      "\u001b[92m3: 3\u001b[1;m\n",
      "\u001b[92m4: 4\u001b[1;m\n",
      "\u001b[92m5: 5\u001b[1;m\n",
      "\u001b[92m6: 6\u001b[1;m\n",
      "\u001b[92m7: 7\u001b[1;m\n",
      "\u001b[92m8: 8\u001b[1;m\n",
      "\u001b[92m9: 9\u001b[1;m\n",
      "\u001b[92m10: 10\u001b[1;m\n",
      "\u001b[92m11: 11\u001b[1;m\n",
      "\u001b[92m12: 12\u001b[1;m\n",
      "\u001b[92m13: 13\u001b[1;m\n",
      "\u001b[92m14: 14\u001b[1;m\n",
      "\u001b[92m15: 15\u001b[1;m\n",
      "\u001b[92m16: 16\u001b[1;m\n",
      "\u001b[92m17: 17\u001b[1;m\n",
      "\u001b[92m18: 18\u001b[1;m\n",
      "\u001b[92m19: 19\u001b[1;m\n",
      "\u001b[92m20: 20\u001b[1;m\n",
      "\u001b[92m21: 21\u001b[1;m\n",
      "\u001b[92m22: 22\u001b[1;m\n",
      "\u001b[92m23: 23\u001b[1;m\n",
      "\u001b[92m24: 24\u001b[1;m\n",
      "\u001b[92m25: 25\u001b[1;m\n",
      "\u001b[92m26: 26\u001b[1;m\n",
      "\u001b[92m27: 27\u001b[1;m\n",
      "\u001b[92m28: 28\u001b[1;m\n",
      "\u001b[92m29: 29\u001b[1;m\n",
      "\u001b[92m30: 30\u001b[1;m\n",
      "\u001b[92m31: 32\u001b[1;m\n",
      "\u001b[92m32: 33\u001b[1;m\n",
      "\u001b[92m33: 34\u001b[1;m\n",
      "\u001b[92m34: 35\u001b[1;m\n",
      "\u001b[92m35: 36\u001b[1;m\n",
      "\u001b[92m36: 37\u001b[1;m\n",
      "\u001b[92m37: 38\u001b[1;m\n",
      "\u001b[92m38: 39\u001b[1;m\n",
      "\u001b[92m39: 40\u001b[1;m\n",
      "\u001b[92m40: 41\u001b[1;m\n",
      "\u001b[92m41: 42\u001b[1;m\n",
      "\u001b[92m42: 43\u001b[1;m\n",
      "\u001b[92m43: 44\u001b[1;m\n",
      "\u001b[1;31m44: unaligned. best cand 304\u001b[1;m\n",
      "\u001b[92m45: 46\u001b[1;m\n",
      "\u001b[92m46: 47\u001b[1;m\n",
      "\u001b[92m47: 48\u001b[1;m\n",
      "\u001b[92m48: 49\u001b[1;m\n",
      "\u001b[92m49: 51\u001b[1;m\n",
      "\u001b[92m50: 52\u001b[1;m\n",
      "\u001b[92m51: 53\u001b[1;m\n",
      "\u001b[92m52: 54\u001b[1;m\n",
      "\u001b[92m53: 55\u001b[1;m\n",
      "\u001b[92m54: 56\u001b[1;m\n",
      "\u001b[92m55: 57\u001b[1;m\n",
      "\u001b[92m56: 58\u001b[1;m\n",
      "\u001b[92m57: 59\u001b[1;m\n",
      "\u001b[92m58: 60\u001b[1;m\n",
      "\u001b[92m59: 61\u001b[1;m\n",
      "\u001b[92m60: 62\u001b[1;m\n",
      "\u001b[92m61: 63\u001b[1;m\n",
      "\u001b[92m62: 64\u001b[1;m\n",
      "\u001b[92m63: 65\u001b[1;m\n",
      "\u001b[92m64: 66\u001b[1;m\n",
      "\u001b[92m65: 67\u001b[1;m\n",
      "\u001b[92m66: 68\u001b[1;m\n",
      "\u001b[1;31m67: unaligned. best cand 248\u001b[1;m\n",
      "\u001b[92m68: 72\u001b[1;m\n",
      "\u001b[92m69: 73\u001b[1;m\n",
      "\u001b[92m70: 74\u001b[1;m\n",
      "\u001b[92m71: 75\u001b[1;m\n",
      "\u001b[92m72: 76\u001b[1;m\n",
      "\u001b[92m73: 77\u001b[1;m\n",
      "\u001b[92m74: 78\u001b[1;m\n",
      "\u001b[92m75: 79\u001b[1;m\n",
      "\u001b[92m76: 80\u001b[1;m\n",
      "\u001b[92m77: 81\u001b[1;m\n",
      "\u001b[92m78: 82\u001b[1;m\n",
      "\u001b[92m79: 83\u001b[1;m\n",
      "\u001b[92m80: 84\u001b[1;m\n",
      "\u001b[92m81: 85\u001b[1;m\n",
      "\u001b[92m82: 87\u001b[1;m\n",
      "\u001b[1;31m83: unaligned. best cand []\u001b[1;m\n",
      "\u001b[1;31m84: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m85: 90\u001b[1;m\n",
      "\u001b[92m86: 91\u001b[1;m\n",
      "\u001b[92m87: 92\u001b[1;m\n",
      "\u001b[92m88: 93\u001b[1;m\n",
      "\u001b[92m89: 94\u001b[1;m\n",
      "\u001b[92m90: 95\u001b[1;m\n",
      "\u001b[92m91: 96\u001b[1;m\n",
      "\u001b[92m92: 98\u001b[1;m\n",
      "\u001b[92m93: 99\u001b[1;m\n",
      "\u001b[1;31m94: unaligned. best cand 113\u001b[1;m\n",
      "\u001b[92m95: 102\u001b[1;m\n",
      "\u001b[92m96: 104\u001b[1;m\n",
      "\u001b[92m97: 105\u001b[1;m\n",
      "\u001b[92m98: 106\u001b[1;m\n",
      "\u001b[92m99: 107\u001b[1;m\n",
      "\u001b[92m100: 108\u001b[1;m\n",
      "\u001b[92m101: 110\u001b[1;m\n",
      "\u001b[92m102: 111\u001b[1;m\n",
      "\u001b[92m103: 112\u001b[1;m\n",
      "\u001b[92m104: 114\u001b[1;m\n",
      "\u001b[92m105: 115\u001b[1;m\n",
      "\u001b[92m106: 117\u001b[1;m\n",
      "\u001b[92m107: 118\u001b[1;m\n",
      "\u001b[92m108: 119\u001b[1;m\n",
      "\u001b[92m109: 120\u001b[1;m\n",
      "\u001b[92m110: 121\u001b[1;m\n",
      "\u001b[92m111: 122\u001b[1;m\n",
      "\u001b[92m112: 123\u001b[1;m\n",
      "\u001b[92m113: 124\u001b[1;m\n",
      "\u001b[92m114: 125\u001b[1;m\n",
      "\u001b[92m115: 126\u001b[1;m\n",
      "\u001b[92m116: 127\u001b[1;m\n",
      "\u001b[92m117: 128\u001b[1;m\n",
      "\u001b[92m118: 129\u001b[1;m\n",
      "\u001b[92m119: 130\u001b[1;m\n",
      "\u001b[92m120: 131\u001b[1;m\n",
      "\u001b[1;31m121: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m122: 133\u001b[1;m\n",
      "\u001b[1;31m123: unaligned. best cand 231\u001b[1;m\n",
      "\u001b[92m124: 135\u001b[1;m\n",
      "\u001b[92m125: 136\u001b[1;m\n",
      "\u001b[92m126: 137\u001b[1;m\n",
      "\u001b[92m127: 138\u001b[1;m\n",
      "\u001b[92m128: 139\u001b[1;m\n",
      "\u001b[92m129: 140\u001b[1;m\n",
      "\u001b[92m130: 141\u001b[1;m\n",
      "\u001b[92m131: 142\u001b[1;m\n",
      "\u001b[92m132: 143\u001b[1;m\n",
      "\u001b[92m133: 144\u001b[1;m\n",
      "\u001b[92m134: 145\u001b[1;m\n",
      "\u001b[92m135: 146\u001b[1;m\n",
      "\u001b[92m136: 147\u001b[1;m\n",
      "\u001b[92m137: 148\u001b[1;m\n",
      "\u001b[1;31m138: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m139: 150\u001b[1;m\n",
      "\u001b[92m140: 152\u001b[1;m\n",
      "\u001b[92m141: 153\u001b[1;m\n",
      "\u001b[1;31m142: unaligned. best cand 37\u001b[1;m\n",
      "\u001b[92m143: 155\u001b[1;m\n",
      "\u001b[92m144: 156\u001b[1;m\n",
      "\u001b[92m145: 157\u001b[1;m\n",
      "\u001b[92m146: 158\u001b[1;m\n",
      "\u001b[92m147: 159\u001b[1;m\n",
      "\u001b[92m148: 160\u001b[1;m\n",
      "\u001b[92m149: 161\u001b[1;m\n",
      "\u001b[92m150: 162\u001b[1;m\n",
      "\u001b[92m151: 163\u001b[1;m\n",
      "\u001b[92m152: 164\u001b[1;m\n",
      "\u001b[92m153: 165\u001b[1;m\n",
      "\u001b[92m154: 167\u001b[1;m\n",
      "\u001b[1;31m155: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m156: 169\u001b[1;m\n",
      "\u001b[92m157: 170\u001b[1;m\n",
      "\u001b[92m158: 172\u001b[1;m\n",
      "\u001b[92m159: 173\u001b[1;m\n",
      "\u001b[92m160: 174\u001b[1;m\n",
      "\u001b[92m161: 175\u001b[1;m\n",
      "\u001b[92m162: 176\u001b[1;m\n",
      "\u001b[92m163: 177\u001b[1;m\n",
      "\u001b[92m164: 178\u001b[1;m\n",
      "\u001b[92m165: 179\u001b[1;m\n",
      "\u001b[92m166: 180\u001b[1;m\n",
      "\u001b[92m167: 181\u001b[1;m\n",
      "\u001b[92m168: 182\u001b[1;m\n",
      "\u001b[92m169: 183\u001b[1;m\n",
      "\u001b[92m170: 184\u001b[1;m\n",
      "\u001b[92m171: 185\u001b[1;m\n",
      "\u001b[92m172: 186\u001b[1;m\n",
      "\u001b[92m173: 187\u001b[1;m\n",
      "\u001b[92m174: 188\u001b[1;m\n",
      "\u001b[92m175: 189\u001b[1;m\n",
      "\u001b[92m176: 190\u001b[1;m\n",
      "\u001b[92m177: 191\u001b[1;m\n",
      "\u001b[92m178: 192\u001b[1;m\n",
      "\u001b[92m179: 193\u001b[1;m\n",
      "\u001b[1;31m180: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m181: 195\u001b[1;m\n",
      "\u001b[92m182: 196\u001b[1;m\n",
      "\u001b[92m183: 197\u001b[1;m\n",
      "\u001b[92m184: 198\u001b[1;m\n",
      "\u001b[92m185: 199\u001b[1;m\n",
      "\u001b[92m186: 200\u001b[1;m\n",
      "\u001b[92m187: 201\u001b[1;m\n",
      "\u001b[92m188: 202\u001b[1;m\n",
      "\u001b[92m189: 203\u001b[1;m\n",
      "\u001b[92m190: 204\u001b[1;m\n",
      "\u001b[92m191: 205\u001b[1;m\n",
      "\u001b[92m192: 206\u001b[1;m\n",
      "\u001b[92m193: 207\u001b[1;m\n",
      "\u001b[92m194: 208\u001b[1;m\n",
      "\u001b[1;31m195: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m196: 210\u001b[1;m\n",
      "\u001b[92m197: 211\u001b[1;m\n",
      "\u001b[92m198: 212\u001b[1;m\n",
      "\u001b[92m199: 213\u001b[1;m\n",
      "\u001b[92m200: 214\u001b[1;m\n",
      "\u001b[92m201: 215\u001b[1;m\n",
      "\u001b[92m202: 216\u001b[1;m\n",
      "\u001b[92m203: 217\u001b[1;m\n",
      "\u001b[92m204: 218\u001b[1;m\n",
      "\u001b[92m205: 219\u001b[1;m\n",
      "\u001b[92m206: 220\u001b[1;m\n",
      "\u001b[92m207: 221\u001b[1;m\n",
      "\u001b[92m208: 222\u001b[1;m\n",
      "\u001b[92m209: 223\u001b[1;m\n",
      "\u001b[92m210: 224\u001b[1;m\n",
      "\u001b[1;31m211: unaligned. best cand 196\u001b[1;m\n",
      "\u001b[92m212: 226\u001b[1;m\n",
      "\u001b[92m213: 227\u001b[1;m\n",
      "\u001b[1;31m214: unaligned. best cand 113\u001b[1;m\n",
      "\u001b[1;31m215: unaligned. best cand 103\u001b[1;m\n",
      "\u001b[92m216: 230\u001b[1;m\n",
      "\u001b[92m217: 231\u001b[1;m\n",
      "\u001b[92m218: 232\u001b[1;m\n",
      "\u001b[92m219: 233\u001b[1;m\n",
      "\u001b[92m220: 234\u001b[1;m\n",
      "\u001b[92m221: 235\u001b[1;m\n",
      "\u001b[92m222: 236\u001b[1;m\n",
      "\u001b[92m223: 237\u001b[1;m\n",
      "\u001b[92m224: 238\u001b[1;m\n",
      "\u001b[92m225: 239\u001b[1;m\n",
      "\u001b[92m226: 240\u001b[1;m\n",
      "\u001b[92m227: 241\u001b[1;m\n",
      "\u001b[92m228: 242\u001b[1;m\n",
      "\u001b[92m229: 243\u001b[1;m\n",
      "\u001b[92m230: 244\u001b[1;m\n",
      "\u001b[92m231: 245\u001b[1;m\n",
      "\u001b[92m232: 246\u001b[1;m\n",
      "\u001b[92m233: 247\u001b[1;m\n",
      "\u001b[92m234: 248\u001b[1;m\n",
      "\u001b[92m235: 249\u001b[1;m\n",
      "\u001b[92m236: 250\u001b[1;m\n",
      "\u001b[92m237: 251\u001b[1;m\n",
      "\u001b[1;31m238: unaligned. best cand 133\u001b[1;m\n",
      "\u001b[92m239: 253\u001b[1;m\n",
      "\u001b[92m240: 255\u001b[1;m\n",
      "\u001b[92m241: 256\u001b[1;m\n",
      "\u001b[92m242: 257\u001b[1;m\n",
      "\u001b[92m243: 258\u001b[1;m\n",
      "\u001b[92m244: 260\u001b[1;m\n",
      "\u001b[92m245: 262\u001b[1;m\n",
      "\u001b[92m246: 263\u001b[1;m\n",
      "\u001b[92m247: 265\u001b[1;m\n",
      "\u001b[92m248: 266\u001b[1;m\n",
      "\u001b[92m249: 267\u001b[1;m\n",
      "\u001b[92m250: 268\u001b[1;m\n",
      "\u001b[92m251: 269\u001b[1;m\n",
      "\u001b[1;31m252: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m253: 272\u001b[1;m\n",
      "\u001b[92m254: 273\u001b[1;m\n",
      "\u001b[1;31m255: unaligned. best cand 37\u001b[1;m\n",
      "\u001b[92m256: 275\u001b[1;m\n",
      "\u001b[92m257: 277\u001b[1;m\n",
      "\u001b[92m258: 278\u001b[1;m\n",
      "\u001b[92m259: 279\u001b[1;m\n",
      "\u001b[92m260: 280\u001b[1;m\n",
      "\u001b[92m261: 281\u001b[1;m\n",
      "\u001b[92m262: 282\u001b[1;m\n",
      "\u001b[1;31m263: unaligned. best cand 112\u001b[1;m\n",
      "\u001b[92m264: 284\u001b[1;m\n",
      "\u001b[92m265: 285\u001b[1;m\n",
      "\u001b[92m266: 286\u001b[1;m\n",
      "\u001b[92m267: 287\u001b[1;m\n",
      "\u001b[92m268: 289\u001b[1;m\n",
      "\u001b[92m269: 290\u001b[1;m\n",
      "\u001b[92m270: 291\u001b[1;m\n",
      "\u001b[92m271: 292\u001b[1;m\n",
      "\u001b[92m272: 293\u001b[1;m\n",
      "\u001b[92m273: 294\u001b[1;m\n",
      "\u001b[92m274: 295\u001b[1;m\n",
      "\u001b[92m275: 296\u001b[1;m\n",
      "\u001b[92m276: 297\u001b[1;m\n",
      "\u001b[92m277: 298\u001b[1;m\n",
      "\u001b[92m278: 299\u001b[1;m\n",
      "\u001b[92m279: 300\u001b[1;m\n",
      "\u001b[92m280: 301\u001b[1;m\n",
      "\u001b[92m281: 302\u001b[1;m\n",
      "\u001b[92m282: 303\u001b[1;m\n",
      "\u001b[92m283: 304\u001b[1;m\n",
      "\u001b[92m284: 305\u001b[1;m\n",
      "\u001b[92m285: 306\u001b[1;m\n",
      "\u001b[92m286: 307\u001b[1;m\n",
      "\u001b[92m287: 308\u001b[1;m\n",
      "\u001b[92m288: 309\u001b[1;m\n",
      "\u001b[92m289: 311\u001b[1;m\n",
      "\u001b[92m290: 312\u001b[1;m\n",
      "\u001b[1;31m291: unaligned. best cand 112\u001b[1;m\n",
      "\u001b[92m292: 314\u001b[1;m\n",
      "\u001b[92m293: 315\u001b[1;m\n",
      "\u001b[92m294: 316\u001b[1;m\n",
      "\u001b[92m295: 317\u001b[1;m\n",
      "\u001b[92m296: 318\u001b[1;m\n",
      "\u001b[92m297: 319\u001b[1;m\n",
      "\u001b[92m298: 320\u001b[1;m\n",
      "\u001b[92m299: 321\u001b[1;m\n",
      "\u001b[92m300: 322\u001b[1;m\n",
      "\u001b[92m301: 323\u001b[1;m\n",
      "\u001b[92m302: 324\u001b[1;m\n",
      "\u001b[92m303: 325\u001b[1;m\n",
      "\u001b[92m304: 326\u001b[1;m\n",
      "\u001b[92m305: 327\u001b[1;m\n",
      "\u001b[92m306: 328\u001b[1;m\n",
      "\u001b[92m307: 329\u001b[1;m\n",
      "\u001b[92m308: 330\u001b[1;m\n",
      "\u001b[92m309: 331\u001b[1;m\n",
      "\u001b[92m310: 332\u001b[1;m\n",
      "\u001b[92m311: 333\u001b[1;m\n",
      "\u001b[92m312: 334\u001b[1;m\n",
      "\u001b[92m313: 335\u001b[1;m\n",
      "\u001b[1;31m314: unaligned. best cand 103\u001b[1;m\n",
      "\u001b[1;31m315: unaligned. best cand 130\u001b[1;m\n",
      "\u001b[92m316: 338\u001b[1;m\n",
      "\u001b[92m317: 339\u001b[1;m\n",
      "\u001b[92m318: 341\u001b[1;m\n",
      "\u001b[1;31m319: unaligned. best cand 341\u001b[1;m\n",
      "\u001b[92m320: 343\u001b[1;m\n",
      "\n",
      "298 out of 321 source sentences aligned by BLEU 92.8348909657%\n",
      "after gap filling, 318 out of 321 source sentences aligned 99.0654205607%\n",
      "after gap filling, 338 out of 344 target sentences aligned 98.2558139535%\n",
      "alignment: 0 - 0\n",
      "alignment: 1 - 1\n",
      "alignment: 2 - 2\n",
      "alignment: 3 - 3\n",
      "alignment: 4 - 4\n",
      "alignment: 5 - 5\n",
      "alignment: 6 - 6\n",
      "alignment: 7 - 7\n",
      "alignment: 8 - 8\n",
      "alignment: 9 - 9\n",
      "alignment: 10 - 10\n",
      "alignment: 11 - 11\n",
      "alignment: 12 - 12\n",
      "alignment: 13 - 13\n",
      "alignment: 14 - 14\n",
      "alignment: 15 - 15\n",
      "alignment: 16 - 16\n",
      "alignment: 17 - 17\n",
      "alignment: 18 - 18\n",
      "alignment: 19 - 19\n",
      "alignment: 20 - 20\n",
      "alignment: 21 - 21\n",
      "alignment: 22 - 22\n",
      "alignment: 23 - 23\n",
      "alignment: 24 - 24\n",
      "alignment: 25 - 25\n",
      "alignment: 26 - 26\n",
      "alignment: 27 - 27\n",
      "alignment: 28 - 28\n",
      "alignment: 29 - 29\n",
      "alignment: 30 - 30,31\n",
      "alignment: 31 - 32\n",
      "alignment: 32 - 33\n",
      "alignment: 33 - 34\n",
      "alignment: 34 - 35\n",
      "alignment: 35 - 36\n",
      "alignment: 36 - 37\n",
      "alignment: 37 - 38\n",
      "alignment: 38 - 39\n",
      "alignment: 39 - 40\n",
      "alignment: 40 - 41\n",
      "alignment: 41 - 42\n",
      "alignment: 42 - 43\n",
      "alignment: 43 - 44\n",
      "alignment: 45 - 45,46\n",
      "alignment: 46 - 47\n",
      "alignment: 47 - 48\n",
      "alignment: 48 - 49\n",
      "alignment: 49 - 51\n",
      "alignment: 50 - 52\n",
      "alignment: 51 - 53\n",
      "alignment: 52 - 54\n",
      "alignment: 53 - 55\n",
      "alignment: 54 - 56\n",
      "alignment: 55 - 57\n",
      "alignment: 56 - 58\n",
      "alignment: 57 - 59\n",
      "alignment: 58 - 60\n",
      "alignment: 59 - 61\n",
      "alignment: 60 - 62\n",
      "alignment: 61 - 63\n",
      "alignment: 62 - 64\n",
      "alignment: 63 - 65\n",
      "alignment: 64 - 66\n",
      "alignment: 65 - 67\n",
      "alignment: 66 - 68,69\n",
      "alignment: 67 - 71\n",
      "alignment: 68 - 72\n",
      "alignment: 69 - 73\n",
      "alignment: 70 - 74\n",
      "alignment: 71 - 75\n",
      "alignment: 72 - 76\n",
      "alignment: 73 - 77\n",
      "alignment: 74 - 78\n",
      "alignment: 75 - 79\n",
      "alignment: 76 - 80\n",
      "alignment: 77 - 81\n",
      "alignment: 78 - 82\n",
      "alignment: 79 - 83\n",
      "alignment: 80 - 84\n",
      "alignment: 81 - 85\n",
      "alignment: 82 - 86,87\n",
      "alignment: 83 - 88\n",
      "alignment: 84 - 89\n",
      "alignment: 85 - 90\n",
      "alignment: 86 - 91\n",
      "alignment: 87 - 92\n",
      "alignment: 88 - 93\n",
      "alignment: 89 - 94\n",
      "alignment: 90 - 95\n",
      "alignment: 91 - 96,97\n",
      "alignment: 92 - 98\n",
      "alignment: 93 - 99,100\n",
      "alignment: 95 - 101,102,103\n",
      "alignment: 96 - 104\n",
      "alignment: 97 - 105\n",
      "alignment: 98 - 106\n",
      "alignment: 99 - 107\n",
      "alignment: 100 - 108,109\n",
      "alignment: 101 - 110\n",
      "alignment: 102 - 111\n",
      "alignment: 103 - 112\n",
      "alignment: 104 - 114\n",
      "alignment: 105 - 115,116\n",
      "alignment: 106 - 117\n",
      "alignment: 107 - 118\n",
      "alignment: 108 - 119\n",
      "alignment: 109 - 120\n",
      "alignment: 110 - 121\n",
      "alignment: 111 - 122\n",
      "alignment: 112 - 123\n",
      "alignment: 113 - 124\n",
      "alignment: 114 - 125\n",
      "alignment: 115 - 126\n",
      "alignment: 116 - 127\n",
      "alignment: 117 - 128\n",
      "alignment: 118 - 129\n",
      "alignment: 119 - 130\n",
      "alignment: 120 - 131\n",
      "alignment: 121 - 132\n",
      "alignment: 122 - 133\n",
      "alignment: 123 - 134\n",
      "alignment: 124 - 135\n",
      "alignment: 125 - 136\n",
      "alignment: 126 - 137\n",
      "alignment: 127 - 138\n",
      "alignment: 128 - 139\n",
      "alignment: 129 - 140\n",
      "alignment: 130 - 141\n",
      "alignment: 131 - 142\n",
      "alignment: 132 - 143\n",
      "alignment: 133 - 144\n",
      "alignment: 134 - 145\n",
      "alignment: 135 - 146\n",
      "alignment: 136 - 147\n",
      "alignment: 137 - 148\n",
      "alignment: 139 - 149,150\n",
      "alignment: 140 - 151,152\n",
      "alignment: 141 - 153\n",
      "alignment: 142 - 154\n",
      "alignment: 143 - 155\n",
      "alignment: 144 - 156\n",
      "alignment: 145 - 157\n",
      "alignment: 146 - 158\n",
      "alignment: 147 - 159\n",
      "alignment: 148 - 160\n",
      "alignment: 149 - 161\n",
      "alignment: 150 - 162\n",
      "alignment: 151 - 163\n",
      "alignment: 152 - 164\n",
      "alignment: 153 - 165\n",
      "alignment: 154 - 167\n",
      "alignment: 155 - 168\n",
      "alignment: 156 - 169\n",
      "alignment: 157 - 170\n",
      "alignment: 158 - 171,172\n",
      "alignment: 159 - 173\n",
      "alignment: 160 - 174\n",
      "alignment: 161 - 175\n",
      "alignment: 162 - 176\n",
      "alignment: 163 - 177\n",
      "alignment: 164 - 178\n",
      "alignment: 165 - 179\n",
      "alignment: 166 - 180\n",
      "alignment: 167 - 181\n",
      "alignment: 168 - 182\n",
      "alignment: 169 - 183\n",
      "alignment: 170 - 184\n",
      "alignment: 171 - 185\n",
      "alignment: 172 - 186\n",
      "alignment: 173 - 187\n",
      "alignment: 174 - 188\n",
      "alignment: 175 - 189\n",
      "alignment: 176 - 190\n",
      "alignment: 177 - 191\n",
      "alignment: 178 - 192\n",
      "alignment: 179 - 193\n",
      "alignment: 180 - 194\n",
      "alignment: 181 - 195\n",
      "alignment: 182 - 196\n",
      "alignment: 183 - 197\n",
      "alignment: 184 - 198\n",
      "alignment: 185 - 199\n",
      "alignment: 186 - 200\n",
      "alignment: 187 - 201\n",
      "alignment: 188 - 202\n",
      "alignment: 189 - 203\n",
      "alignment: 190 - 204\n",
      "alignment: 191 - 205\n",
      "alignment: 192 - 206\n",
      "alignment: 193 - 207\n",
      "alignment: 194 - 208\n",
      "alignment: 195 - 209\n",
      "alignment: 196 - 210\n",
      "alignment: 197 - 211\n",
      "alignment: 198 - 212\n",
      "alignment: 199 - 213\n",
      "alignment: 200 - 214\n",
      "alignment: 201 - 215\n",
      "alignment: 202 - 216\n",
      "alignment: 203 - 217\n",
      "alignment: 204 - 218\n",
      "alignment: 205 - 219\n",
      "alignment: 206 - 220\n",
      "alignment: 207 - 221\n",
      "alignment: 208 - 222\n",
      "alignment: 209 - 223\n",
      "alignment: 210 - 224\n",
      "alignment: 211 - 225\n",
      "alignment: 212 - 226\n",
      "alignment: 213 - 227\n",
      "alignment: 214 - 228\n",
      "alignment: 215 - 229\n",
      "alignment: 216 - 230\n",
      "alignment: 217 - 231\n",
      "alignment: 218 - 232\n",
      "alignment: 219 - 233\n",
      "alignment: 220 - 234\n",
      "alignment: 221 - 235\n",
      "alignment: 222 - 236\n",
      "alignment: 223 - 237\n",
      "alignment: 224 - 238\n",
      "alignment: 225 - 239\n",
      "alignment: 226 - 240\n",
      "alignment: 227 - 241\n",
      "alignment: 228 - 242\n",
      "alignment: 229 - 243\n",
      "alignment: 230 - 244\n",
      "alignment: 231 - 245\n",
      "alignment: 232 - 246\n",
      "alignment: 233 - 247\n",
      "alignment: 234 - 248\n",
      "alignment: 235 - 249\n",
      "alignment: 236 - 250\n",
      "alignment: 237 - 251\n",
      "alignment: 238 - 252\n",
      "alignment: 239 - 253\n",
      "alignment: 240 - 254,255\n",
      "alignment: 241 - 256\n",
      "alignment: 242 - 257\n",
      "alignment: 243 - 258\n",
      "alignment: 244 - 259,260,261\n",
      "alignment: 245 - 262\n",
      "alignment: 246 - 263\n",
      "alignment: 247 - 264,265\n",
      "alignment: 248 - 266\n",
      "alignment: 249 - 267\n",
      "alignment: 250 - 268\n",
      "alignment: 251 - 269,270\n",
      "alignment: 252 - 271\n",
      "alignment: 253 - 272\n",
      "alignment: 254 - 273\n",
      "alignment: 255 - 274\n",
      "alignment: 256 - 275\n",
      "alignment: 257 - 276,277\n",
      "alignment: 258 - 278\n",
      "alignment: 259 - 279\n",
      "alignment: 260 - 280\n",
      "alignment: 261 - 281\n",
      "alignment: 262 - 282\n",
      "alignment: 263 - 283\n",
      "alignment: 264 - 284\n",
      "alignment: 265 - 285\n",
      "alignment: 266 - 286\n",
      "alignment: 267 - 287\n",
      "alignment: 268 - 289\n",
      "alignment: 269 - 290\n",
      "alignment: 270 - 291\n",
      "alignment: 271 - 292\n",
      "alignment: 272 - 293\n",
      "alignment: 273 - 294\n",
      "alignment: 274 - 295\n",
      "alignment: 275 - 296\n",
      "alignment: 276 - 297\n",
      "alignment: 277 - 298\n",
      "alignment: 278 - 299\n",
      "alignment: 279 - 300\n",
      "alignment: 280 - 301\n",
      "alignment: 281 - 302\n",
      "alignment: 282 - 303\n",
      "alignment: 283 - 304\n",
      "alignment: 284 - 305\n",
      "alignment: 285 - 306\n",
      "alignment: 286 - 307\n",
      "alignment: 287 - 308\n",
      "alignment: 288 - 309,310\n",
      "alignment: 289 - 311\n",
      "alignment: 290 - 312\n",
      "alignment: 291 - 313\n",
      "alignment: 292 - 314\n",
      "alignment: 293 - 315\n",
      "alignment: 294 - 316\n",
      "alignment: 295 - 317\n",
      "alignment: 296 - 318\n",
      "alignment: 297 - 319\n",
      "alignment: 298 - 320\n",
      "alignment: 299 - 321\n",
      "alignment: 300 - 322\n",
      "alignment: 301 - 323\n",
      "alignment: 302 - 324\n",
      "alignment: 303 - 325\n",
      "alignment: 304 - 326\n",
      "alignment: 305 - 327\n",
      "alignment: 306 - 328\n",
      "alignment: 307 - 329\n",
      "alignment: 308 - 330\n",
      "alignment: 309 - 331\n",
      "alignment: 310 - 332\n",
      "alignment: 311 - 333\n",
      "alignment: 312 - 334\n",
      "alignment: 313 - 335\n",
      "alignment: 314,315 - 336\n",
      "alignment: 316 - 338\n",
      "alignment: 317 - 339\n",
      "alignment: 318 - 340,341\n",
      "alignment: 319 - 342\n",
      "alignment: 320 - 343\n",
      "\n",
      "finished with article\n",
      "\n",
      "====================\n",
      "\n",
      "sentence alignment took 1.8402040004730225 seconds\n"
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "start = time.time()\n",
    "!./bleualign.py -s texts/russian/sourcetextforbleualign.txt -t texts/russian/targettextforbleualign.txt --srctotarget texts/russian/translatedsource.txt -o texts/russian/outputfile --verbosity 2\n",
    "end = time.time()\n",
    "print(f'sentence alignment took {end-start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [START HERE] 3. Read sentence-aligned files (from Bleualign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'texts/{srclang}/outputfile-s','r') as f:\n",
    "    alignedsrc = f.read().split('\\n')\n",
    "with open(f'texts/{srclang}/outputfile-t','r') as f:\n",
    "    alignedtgt = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' على أنه لم يكن يستطيع أن يبلو من شاطئ هذه القناة مسافة بعيدة، فقد كان هذا الشاطئ محفوفًا عن يمينه وعن شماله بالخطر.',\n",
       " 'However, he was not able to explore along the bank of the canal for a great distance, inasmuch as both to right and to left the way was fraught with danger.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = random.choice(range(len(alignedsrc)))\n",
    "alignedsrc[i], alignedtgt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/164 sentences parsed.\n",
      "100/164 sentences parsed.\n",
      "150/164 sentences parsed.\n"
     ]
    }
   ],
   "source": [
    "# sent to sent alignment\n",
    "oneLinesrc, oneLineEng = rawsrcsents, rawtgtsents\n",
    "alignedsrc, alignedEng = alignedsrc, alignedtgt\n",
    "sentAlignments = []\n",
    "alignmentLookup = dict()\n",
    "srcIndex = 0\n",
    "for alignsrcSent, alignEngSent in zip(alignedsrc, alignedEng):\n",
    "    if srcIndex % 50 == 0:\n",
    "        print(f'{srcIndex}/{len(rawsrcsents)} sentences parsed.')\n",
    "    individualEngSents = [sent.text for sent in engNLP(alignEngSent).sents]\n",
    "    for indEngSent in individualEngSents:\n",
    "        for i, thisEngLine in enumerate(oneLineEng):\n",
    "            if indEngSent.strip() == thisEngLine.strip():\n",
    "                engIndex = i\n",
    "        for j, thissrcLine in enumerate(oneLinesrc):\n",
    "            if alignsrcSent.strip() == thissrcLine.strip():\n",
    "                srcIndex = j\n",
    "        sentAlignments.append({\n",
    "            'indices' : (srcIndex, engIndex),\n",
    "            'sents' : (oneLinesrc[srcIndex], oneLineEng[engIndex])\n",
    "        })\n",
    "        alignmentLookup.setdefault(srcIndex,[])\n",
    "        alignmentLookup[srcIndex].append(engIndex)\n",
    "    srcIndex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'jsondata/{srclang}/sentAlignment4-11.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sentAlignments, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE DONT NEED - check it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " كان جده هذا ثقيل الظل بغيضًا إليه، وكان يقضي في البيت فصل الشتاء من كل سنة، وكان قد صلح ونسك حين اضطرته الحياة إلى الصلاح والنسك، فكان يصلي الخمس لأوقاتها، ولم يكن لسانه يفتر عن ذكر الله.\n",
      "This grandfather of his was to him an unattractive and odious person, who used to spend every winter at the house.\n"
     ]
    }
   ],
   "source": [
    "# chec, k it works\n",
    "randSentAlign = random.choice(sentAlignments)\n",
    "s, t = randSentAlign['sents']\n",
    "print(s)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Parse word alignment using SimAlign (recommended: fast and high coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install simalign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022-04-15 10:21:00,693 - simalign.simalign - INFO - Initialized the EmbeddingLoader with model: bert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading word aligner tool took 9.31760287284851 seconds\n"
     ]
    }
   ],
   "source": [
    "from simalign import SentenceAligner\n",
    "start = time.time()\n",
    "# making an instance of our model.\n",
    "# You can specify the embedding model and all alignment settings in the constructor.\n",
    "myaligner = SentenceAligner(model=\"bert\", token_type=\"bpe\", matching_methods=\"mai\")\n",
    "end = time.time()\n",
    "print(f'downloading word aligner tool took {end-start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate word alignment with SimAlign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 233)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rawsrcsents), len(rawtgtsents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/164 sentences parsed in 0.0006680488586425781 s.\n",
      "25/164 sentences parsed in 153.3745470046997 s.\n",
      "50/164 sentences parsed in 254.79790997505188 s.\n",
      "75/164 sentences parsed in 297.28424286842346 s.\n",
      "100/164 sentences parsed in 363.3640058040619 s.\n",
      "125/164 sentences parsed in 449.0529410839081 s.\n",
      "150/164 sentences parsed in 528.0997431278229 s.\n",
      "parsed in 577.4362461566925 s\n"
     ]
    }
   ],
   "source": [
    "# get rid of white space at end\n",
    "your_data = zip(rawsrcsents, rawtgtsents)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "wordAlignmentList = []\n",
    "\n",
    "for i, srcsent in enumerate(rawsrcsents):\n",
    "    if i % 25 == 0:\n",
    "        currently = time.time()\n",
    "        print(f\"{i}/{len(rawsrcsents)} sentences parsed in {currently-start} s.\")\n",
    "        \n",
    "    srcTokens = []\n",
    "    if srclang != 'Arabic':\n",
    "        srcDoc = sourceNLP(srcsent)\n",
    "\n",
    "        for token in srcDoc:\n",
    "            srcTokens.append({\n",
    "                'tokenid' : token.idx,\n",
    "                'pos' : token.pos_, \n",
    "                'text' : token.text, \n",
    "                'lemma' : token.lemma_,\n",
    "                'features' : Morphology.feats_to_dict(str(token.morph))\n",
    "            })\n",
    "    else:\n",
    "        srcDoc = araby.tokenize(srcsent)\n",
    "        for tidx, token in enumerate(srcDoc):\n",
    "            srcTokens.append({\n",
    "                'tokenid' : tidx,\n",
    "                'pos' : 'N/A', \n",
    "                'text' : token, \n",
    "                'lemma' : token,\n",
    "                'features' : 'N/A'\n",
    "            })\n",
    "\n",
    "    try:\n",
    "        jLst = alignmentLookup[i]\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    for j in jLst:\n",
    "        tgtDoc = engNLP(rawtgtsents[j])\n",
    "\n",
    "        tgtTokens = []\n",
    "        for token in tgtDoc:\n",
    "            tgtTokens.append({\n",
    "                'tokenid' : token.idx,\n",
    "                'pos' : token.pos_, \n",
    "                'text' : token.text, \n",
    "                'lemma' : token.lemma_,\n",
    "                'features' : Morphology.feats_to_dict(str(token.morph))\n",
    "            })\n",
    "\n",
    "        if srclang != 'Arabic':\n",
    "            src = [t.text for t in srcDoc]\n",
    "        else:\n",
    "            src = srcDoc\n",
    "            \n",
    "        tgt = [t.text for t in tgtDoc]\n",
    "\n",
    "        alignments = myaligner.get_word_aligns(src, tgt)\n",
    "        itermax = alignments['itermax']\n",
    "\n",
    "        wordAlignmentList.append({\n",
    "            'alignedwordindices' : itermax,\n",
    "            'alignedwords' : [(src[s], tgt[t]) for s, t in itermax],\n",
    "            'srctokens' : srcTokens,\n",
    "            'tgttokens' : tgtTokens,\n",
    "            'srcsentidx' : i,\n",
    "            'tgtsentidx' : j,\n",
    "        })\n",
    "end = time.time()\n",
    "print('parsed in',end-start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'jsondata/{srclang}/wordAlignment4-11.json', 'w',encoding='utf-8') as f:\n",
    "    json.dump(wordAlignmentList, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "srctokens = []\n",
    "tgttokens = []\n",
    "for srcsent in rawsrcsents:\n",
    "    srcdoc = sourceNLP(srcsent)\n",
    "    senttokens = [{\n",
    "            'tokenid' : token.idx,\n",
    "            'pos' : token.pos_, \n",
    "            'text' : token.text, \n",
    "            'lemma' : token.lemma_,\n",
    "            'features' : Morphology.feats_to_dict(str(token.morph)),\n",
    "            'linebreak' : False\n",
    "        } for token in srcdoc]\n",
    "    srctokens.append({\n",
    "        'text' : srcsent,\n",
    "        'tokens' : senttokens\n",
    "    })\n",
    "for tgtsent in rawtgtsents:\n",
    "    tgtdoc = engNLP(tgtsent)\n",
    "    senttokens = [{\n",
    "            'tokenid' : token.idx,\n",
    "            'pos' : token.pos_, \n",
    "            'text' : token.text, \n",
    "            'lemma' : token.lemma_,\n",
    "            'features' : Morphology.feats_to_dict(str(token.morph)),\n",
    "            'linebreak' : False\n",
    "        } for token in tgtdoc]\n",
    "    tgttokens.append({\n",
    "        'text' : tgtsent,\n",
    "        'tokens' : senttokens\n",
    "    })\n",
    "\n",
    "sentsInOrderJSON = {'srcSentsInOrder' : srctokens, 'tgtSentsInOrder' : tgttokens}\n",
    "with open(f'jsondata/{srclang}/sentsInOrder4-11.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sentsInOrderJSON, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract paragraph breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the module\n",
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "with open(f'jsondata/{srclang}/sentsInOrder4-7.json') as json_file:\n",
    "    sentsInOrder = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcLineBreaks = []\n",
    "for i, s in enumerate(sentsInOrder['srcSentsInOrder']):\n",
    "    for j, t in enumerate(s['tokens']):\n",
    "        islinebreak = t['linebreak']\n",
    "        if islinebreak:\n",
    "            srcLineBreaks.append(str(i) +','+str(j))\n",
    "with open('jsondata/spanish/srcLineBreaks.txt','w') as f:\n",
    "    f.write('\\n'.join(srcLineBreaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtLineBreaks = []\n",
    "for i, s in enumerate(sentsInOrder['tgtSentsInOrder']):\n",
    "    for j, t in enumerate(s['tokens']):\n",
    "        islinebreak = t['linebreak']\n",
    "        if islinebreak:\n",
    "            tgtLineBreaks.append(str(i) +','+str(j))\n",
    "with open('jsondata/spanish/tgtLineBreaks.txt','w') as f:\n",
    "    f.write('\\n'.join(tgtLineBreaks))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
