{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libraries, modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.morphology import Morphology\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import json\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFY SOURCE LANGUAGE\n",
    "srclang = 'Spanish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install spacy lang models\n",
    "\n",
    "if srclang == 'Spanish':\n",
    "    sourceNLP = spacy.load(\"es_core_news_sm\")\n",
    "elif srclang == 'Russian':\n",
    "    sourceNLP = spacy.load(\"ru_core_news_sm\")\n",
    "    \n",
    "engNLP = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load raw texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'texts/{srclang}/rawsource.txt','r') as f:\n",
    "     sourcetxt = f.read().replace('\\n',' ')\n",
    "with open(f'texts/{srclang}/rawtarget.txt','r') as f:\n",
    "     targettxt = f.read().replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcedoc = sourceNLP(sourcetxt)\n",
    "targetdoc = engNLP(targettxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentenize\n",
    "rawsrcsents = []\n",
    "rawtgtsents = []\n",
    "for sent in sourcedoc.sents:\n",
    "    rawsrcsents.append(sent.text)\n",
    "for sent in targetdoc.sents:\n",
    "    rawtgtsents.append(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write standardized files (one line per sentence) for input to Bleualign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the inputs to bleualign\n",
    "with open(f'texts/{srclang}/sourcetextforbleualign.txt','w') as f:\n",
    "    f.write('\\n'.join(rawsrcsents))\n",
    "with open(f'texts/{srclang}/targettextforbleualign.txt','w') as f:\n",
    "    f.write('\\n'.join(rawtgtsents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized sentences for data output\n",
    "srctokens = []\n",
    "for srcsent in rawsrcsents:\n",
    "    tokens = sourceNLP(srcsent)\n",
    "    srctokens.append([{'text' : t.text, 'lemma' : t.lemma_} for t in tokens])\n",
    "tgttokens = []\n",
    "for tgtsent in rawtgtsents:\n",
    "    tokens = engNLP(tgtsent)\n",
    "    tgttokens.append([{'text' : t.text, 'lemma' : t.lemma_} for t in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Bleualign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install translators --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import translators as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/226 sents translated.\n",
      "25/226 sents translated.\n",
      "50/226 sents translated.\n",
      "75/226 sents translated.\n",
      "100/226 sents translated.\n",
      "125/226 sents translated.\n",
      "problem on  \n",
      "150/226 sents translated.\n",
      "175/226 sents translated.\n",
      "200/226 sents translated.\n",
      "225/226 sents translated.\n",
      "machine translation took 201.71470999717712 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "translatedsourcesents = []\n",
    "for i, sent in enumerate(rawsrcsents):\n",
    "    if i % 25 == 0:\n",
    "        print(f'{i}/{len(rawsrcsents)} sents translated.')\n",
    "    try:\n",
    "        translatedsourcesents.append(ts.google(sent, to_language = 'en'))\n",
    "    except:\n",
    "        print('problem on',sent)\n",
    "        translatedsourcesents.append('\\n')\n",
    "end = time.time()\n",
    "print(f'machine translation took {end-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 226)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rawsrcsents), len(translatedsourcesents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'texts/{srclang}/translatedsource.txt','w') as f:\n",
    "    f.write('\\n'.join(translatedsourcesents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading in article 0: \n",
      "processing\n",
      "computing alignment between srctotarget (file 0) and target text\n",
      "Evaluating sentences with bleu\n",
      "finished\n",
      "searching for longest path of good alignments\n",
      "finished\n",
      "Thu Apr  7 17:17:23 2022\n",
      "filling gaps\n",
      "finished\n",
      "Thu Apr  7 17:17:23 2022\n",
      "Results of BLEU 1-to-1 alignment\n",
      "\u001b[92m0: 0\u001b[1;m\n",
      "\u001b[1;31m1: unaligned. best cand 107\u001b[1;m\n",
      "\u001b[92m2: 2\u001b[1;m\n",
      "\u001b[92m3: 3\u001b[1;m\n",
      "\u001b[92m4: 5\u001b[1;m\n",
      "\u001b[92m5: 6\u001b[1;m\n",
      "\u001b[92m6: 7\u001b[1;m\n",
      "\u001b[92m7: 8\u001b[1;m\n",
      "\u001b[1;31m8: unaligned. best cand 9\u001b[1;m\n",
      "\u001b[92m9: 9\u001b[1;m\n",
      "\u001b[92m10: 10\u001b[1;m\n",
      "\u001b[92m11: 11\u001b[1;m\n",
      "\u001b[92m12: 12\u001b[1;m\n",
      "\u001b[92m13: 15\u001b[1;m\n",
      "\u001b[92m14: 16\u001b[1;m\n",
      "\u001b[92m15: 17\u001b[1;m\n",
      "\u001b[92m16: 18\u001b[1;m\n",
      "\u001b[92m17: 19\u001b[1;m\n",
      "\u001b[92m18: 21\u001b[1;m\n",
      "\u001b[92m19: 22\u001b[1;m\n",
      "\u001b[92m20: 23\u001b[1;m\n",
      "\u001b[1;31m21: unaligned. best cand 38\u001b[1;m\n",
      "\u001b[92m22: 24\u001b[1;m\n",
      "\u001b[92m23: 25\u001b[1;m\n",
      "\u001b[92m24: 27\u001b[1;m\n",
      "\u001b[92m25: 28\u001b[1;m\n",
      "\u001b[92m26: 30\u001b[1;m\n",
      "\u001b[92m27: 31\u001b[1;m\n",
      "\u001b[92m28: 32\u001b[1;m\n",
      "\u001b[92m29: 34\u001b[1;m\n",
      "\u001b[92m30: 35\u001b[1;m\n",
      "\u001b[92m31: 36\u001b[1;m\n",
      "\u001b[92m32: 37\u001b[1;m\n",
      "\u001b[92m33: 39\u001b[1;m\n",
      "\u001b[92m34: 40\u001b[1;m\n",
      "\u001b[92m35: 41\u001b[1;m\n",
      "\u001b[92m36: 42\u001b[1;m\n",
      "\u001b[92m37: 43\u001b[1;m\n",
      "\u001b[92m38: 44\u001b[1;m\n",
      "\u001b[92m39: 45\u001b[1;m\n",
      "\u001b[92m40: 46\u001b[1;m\n",
      "\u001b[92m41: 47\u001b[1;m\n",
      "\u001b[92m42: 48\u001b[1;m\n",
      "\u001b[92m43: 49\u001b[1;m\n",
      "\u001b[92m44: 50\u001b[1;m\n",
      "\u001b[92m45: 51\u001b[1;m\n",
      "\u001b[92m46: 52\u001b[1;m\n",
      "\u001b[92m47: 54\u001b[1;m\n",
      "\u001b[92m48: 55\u001b[1;m\n",
      "\u001b[92m49: 57\u001b[1;m\n",
      "\u001b[92m50: 58\u001b[1;m\n",
      "\u001b[92m51: 59\u001b[1;m\n",
      "\u001b[92m52: 60\u001b[1;m\n",
      "\u001b[92m53: 62\u001b[1;m\n",
      "\u001b[92m54: 63\u001b[1;m\n",
      "\u001b[92m55: 64\u001b[1;m\n",
      "\u001b[92m56: 65\u001b[1;m\n",
      "\u001b[92m57: 66\u001b[1;m\n",
      "\u001b[92m58: 67\u001b[1;m\n",
      "\u001b[92m59: 68\u001b[1;m\n",
      "\u001b[92m60: 69\u001b[1;m\n",
      "\u001b[92m61: 70\u001b[1;m\n",
      "\u001b[92m62: 71\u001b[1;m\n",
      "\u001b[92m63: 72\u001b[1;m\n",
      "\u001b[92m64: 74\u001b[1;m\n",
      "\u001b[92m65: 75\u001b[1;m\n",
      "\u001b[92m66: 76\u001b[1;m\n",
      "\u001b[92m67: 77\u001b[1;m\n",
      "\u001b[92m68: 78\u001b[1;m\n",
      "\u001b[92m69: 80\u001b[1;m\n",
      "\u001b[92m70: 81\u001b[1;m\n",
      "\u001b[1;31m71: unaligned. best cand 13\u001b[1;m\n",
      "\u001b[92m72: 83\u001b[1;m\n",
      "\u001b[92m73: 85\u001b[1;m\n",
      "\u001b[92m74: 86\u001b[1;m\n",
      "\u001b[1;31m75: unaligned. best cand 86\u001b[1;m\n",
      "\u001b[92m76: 88\u001b[1;m\n",
      "\u001b[92m77: 89\u001b[1;m\n",
      "\u001b[92m78: 90\u001b[1;m\n",
      "\u001b[92m79: 91\u001b[1;m\n",
      "\u001b[92m80: 94\u001b[1;m\n",
      "\u001b[92m81: 96\u001b[1;m\n",
      "\u001b[92m82: 98\u001b[1;m\n",
      "\u001b[92m83: 100\u001b[1;m\n",
      "\u001b[92m84: 101\u001b[1;m\n",
      "\u001b[92m85: 102\u001b[1;m\n",
      "\u001b[92m86: 104\u001b[1;m\n",
      "\u001b[92m87: 106\u001b[1;m\n",
      "\u001b[92m88: 107\u001b[1;m\n",
      "\u001b[92m89: 108\u001b[1;m\n",
      "\u001b[92m90: 109\u001b[1;m\n",
      "\u001b[92m91: 110\u001b[1;m\n",
      "\u001b[92m92: 111\u001b[1;m\n",
      "\u001b[92m93: 112\u001b[1;m\n",
      "\u001b[92m94: 113\u001b[1;m\n",
      "\u001b[92m95: 114\u001b[1;m\n",
      "\u001b[92m96: 115\u001b[1;m\n",
      "\u001b[92m97: 116\u001b[1;m\n",
      "\u001b[92m98: 117\u001b[1;m\n",
      "\u001b[92m99: 118\u001b[1;m\n",
      "\u001b[92m100: 120\u001b[1;m\n",
      "\u001b[92m101: 121\u001b[1;m\n",
      "\u001b[92m102: 123\u001b[1;m\n",
      "\u001b[92m103: 124\u001b[1;m\n",
      "\u001b[92m104: 125\u001b[1;m\n",
      "\u001b[92m105: 126\u001b[1;m\n",
      "\u001b[1;31m106: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m107: 128\u001b[1;m\n",
      "\u001b[92m108: 129\u001b[1;m\n",
      "\u001b[92m109: 130\u001b[1;m\n",
      "\u001b[92m110: 132\u001b[1;m\n",
      "\u001b[92m111: 133\u001b[1;m\n",
      "\u001b[92m112: 134\u001b[1;m\n",
      "\u001b[92m113: 136\u001b[1;m\n",
      "\u001b[92m114: 138\u001b[1;m\n",
      "\u001b[92m115: 139\u001b[1;m\n",
      "\u001b[92m116: 140\u001b[1;m\n",
      "\u001b[92m117: 141\u001b[1;m\n",
      "\u001b[1;31m118: unaligned. best cand 228\u001b[1;m\n",
      "\u001b[92m119: 142\u001b[1;m\n",
      "\u001b[92m120: 144\u001b[1;m\n",
      "\u001b[92m121: 145\u001b[1;m\n",
      "\u001b[92m122: 146\u001b[1;m\n",
      "\u001b[92m123: 147\u001b[1;m\n",
      "\u001b[92m124: 148\u001b[1;m\n",
      "\u001b[92m125: 149\u001b[1;m\n",
      "\u001b[92m126: 150\u001b[1;m\n",
      "\u001b[92m127: 153\u001b[1;m\n",
      "\u001b[92m128: 154\u001b[1;m\n",
      "\u001b[1;31m129: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m130: 156\u001b[1;m\n",
      "\u001b[92m131: 158\u001b[1;m\n",
      "\u001b[92m132: 159\u001b[1;m\n",
      "\u001b[92m133: 160\u001b[1;m\n",
      "\u001b[1;31m134: unaligned. best cand 227\u001b[1;m\n",
      "\u001b[1;31m135: unaligned. best cand 143\u001b[1;m\n",
      "\u001b[92m136: 163\u001b[1;m\n",
      "\u001b[92m137: 164\u001b[1;m\n",
      "\u001b[92m138: 167\u001b[1;m\n",
      "\u001b[92m139: 169\u001b[1;m\n",
      "\u001b[92m140: 170\u001b[1;m\n",
      "\u001b[1;31m141: unaligned. best cand 170\u001b[1;m\n",
      "\u001b[1;31m142: unaligned. best cand []\u001b[1;m\n",
      "\u001b[1;31m143: unaligned. best cand []\u001b[1;m\n",
      "\u001b[1;31m144: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m145: 172\u001b[1;m\n",
      "\u001b[1;31m146: unaligned. best cand 249\u001b[1;m\n",
      "\u001b[1;31m147: unaligned. best cand 168\u001b[1;m\n",
      "\u001b[92m148: 176\u001b[1;m\n",
      "\u001b[92m149: 177\u001b[1;m\n",
      "\u001b[92m150: 178\u001b[1;m\n",
      "\u001b[92m151: 179\u001b[1;m\n",
      "\u001b[92m152: 180\u001b[1;m\n",
      "\u001b[92m153: 181\u001b[1;m\n",
      "\u001b[92m154: 182\u001b[1;m\n",
      "\u001b[92m155: 183\u001b[1;m\n",
      "\u001b[92m156: 184\u001b[1;m\n",
      "\u001b[1;31m157: unaligned. best cand 176\u001b[1;m\n",
      "\u001b[92m158: 187\u001b[1;m\n",
      "\u001b[92m159: 188\u001b[1;m\n",
      "\u001b[92m160: 189\u001b[1;m\n",
      "\u001b[92m161: 191\u001b[1;m\n",
      "\u001b[92m162: 192\u001b[1;m\n",
      "\u001b[92m163: 193\u001b[1;m\n",
      "\u001b[92m164: 197\u001b[1;m\n",
      "\u001b[92m165: 198\u001b[1;m\n",
      "\u001b[92m166: 200\u001b[1;m\n",
      "\u001b[92m167: 201\u001b[1;m\n",
      "\u001b[92m168: 202\u001b[1;m\n",
      "\u001b[92m169: 203\u001b[1;m\n",
      "\u001b[1;31m170: unaligned. best cand 181\u001b[1;m\n",
      "\u001b[92m171: 208\u001b[1;m\n",
      "\u001b[92m172: 209\u001b[1;m\n",
      "\u001b[92m173: 211\u001b[1;m\n",
      "\u001b[92m174: 212\u001b[1;m\n",
      "\u001b[92m175: 213\u001b[1;m\n",
      "\u001b[92m176: 214\u001b[1;m\n",
      "\u001b[92m177: 215\u001b[1;m\n",
      "\u001b[92m178: 217\u001b[1;m\n",
      "\u001b[92m179: 218\u001b[1;m\n",
      "\u001b[92m180: 219\u001b[1;m\n",
      "\u001b[92m181: 220\u001b[1;m\n",
      "\u001b[92m182: 221\u001b[1;m\n",
      "\u001b[92m183: 222\u001b[1;m\n",
      "\u001b[1;31m184: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m185: 224\u001b[1;m\n",
      "\u001b[92m186: 226\u001b[1;m\n",
      "\u001b[92m187: 227\u001b[1;m\n",
      "\u001b[92m188: 229\u001b[1;m\n",
      "\u001b[92m189: 231\u001b[1;m\n",
      "\u001b[92m190: 232\u001b[1;m\n",
      "\u001b[92m191: 233\u001b[1;m\n",
      "\u001b[92m192: 237\u001b[1;m\n",
      "\u001b[92m193: 238\u001b[1;m\n",
      "\u001b[92m194: 239\u001b[1;m\n",
      "\u001b[1;31m195: unaligned. best cand 187\u001b[1;m\n",
      "\u001b[92m196: 242\u001b[1;m\n",
      "\u001b[92m197: 245\u001b[1;m\n",
      "\u001b[92m198: 247\u001b[1;m\n",
      "\u001b[92m199: 249\u001b[1;m\n",
      "\u001b[1;31m200: unaligned. best cand 250\u001b[1;m\n",
      "\u001b[92m201: 250\u001b[1;m\n",
      "\u001b[1;31m202: unaligned. best cand 53\u001b[1;m\n",
      "\u001b[92m203: 252\u001b[1;m\n",
      "\u001b[92m204: 253\u001b[1;m\n",
      "\u001b[92m205: 254\u001b[1;m\n",
      "\u001b[92m206: 255\u001b[1;m\n",
      "\u001b[92m207: 256\u001b[1;m\n",
      "\u001b[92m208: 258\u001b[1;m\n",
      "\u001b[1;31m209: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m210: 261\u001b[1;m\n",
      "\u001b[92m211: 262\u001b[1;m\n",
      "\u001b[92m212: 263\u001b[1;m\n",
      "\u001b[92m213: 264\u001b[1;m\n",
      "\u001b[92m214: 265\u001b[1;m\n",
      "\u001b[92m215: 266\u001b[1;m\n",
      "\u001b[92m216: 267\u001b[1;m\n",
      "\u001b[92m217: 269\u001b[1;m\n",
      "\u001b[92m218: 271\u001b[1;m\n",
      "\u001b[1;31m219: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m220: 273\u001b[1;m\n",
      "\u001b[92m221: 274\u001b[1;m\n",
      "\u001b[1;31m222: unaligned. best cand []\u001b[1;m\n",
      "\u001b[92m223: 277\u001b[1;m\n",
      "\u001b[1;31m224: unaligned. best cand 243\u001b[1;m\n",
      "\u001b[1;31m225: unaligned. best cand []\u001b[1;m\n",
      "\n",
      "199 out of 226 source sentences aligned by BLEU 88.0530973451%\n",
      "after gap filling, 221 out of 226 source sentences aligned 97.7876106195%\n",
      "after gap filling, 257 out of 280 target sentences aligned 91.7857142857%\n",
      "alignment: 0 - 0\n",
      "alignment: 1 - 1\n",
      "alignment: 2 - 2\n",
      "alignment: 3 - 3\n",
      "alignment: 4 - 4,5\n",
      "alignment: 5 - 6\n",
      "alignment: 6 - 7\n",
      "alignment: 7 - 8\n",
      "alignment: 8,9 - 9\n",
      "alignment: 10 - 10\n",
      "alignment: 11 - 11\n",
      "alignment: 12 - 12\n",
      "alignment: 13 - 13,14,15\n",
      "alignment: 14 - 16\n",
      "alignment: 15 - 17\n",
      "alignment: 16 - 18\n",
      "alignment: 17 - 19\n",
      "alignment: 18 - 21\n",
      "alignment: 19 - 22\n",
      "alignment: 20,21 - 23\n",
      "alignment: 22 - 24\n",
      "alignment: 23 - 25,26\n",
      "alignment: 24 - 27\n",
      "alignment: 25 - 28,29\n",
      "alignment: 26 - 30\n",
      "alignment: 27 - 31\n",
      "alignment: 28 - 32\n",
      "alignment: 29 - 33,34\n",
      "alignment: 30 - 35\n",
      "alignment: 31 - 36\n",
      "alignment: 32 - 37\n",
      "alignment: 33 - 38,39\n",
      "alignment: 34 - 40\n",
      "alignment: 35 - 41\n",
      "alignment: 36 - 42\n",
      "alignment: 37 - 43\n",
      "alignment: 38 - 44\n",
      "alignment: 39 - 45\n",
      "alignment: 40 - 46\n",
      "alignment: 41 - 47\n",
      "alignment: 42 - 48\n",
      "alignment: 43 - 49\n",
      "alignment: 44 - 50\n",
      "alignment: 45 - 51\n",
      "alignment: 46 - 52\n",
      "alignment: 47 - 53,54\n",
      "alignment: 48 - 55\n",
      "alignment: 49 - 56,57\n",
      "alignment: 50 - 58\n",
      "alignment: 51 - 59\n",
      "alignment: 52 - 60\n",
      "alignment: 53 - 61,62\n",
      "alignment: 54 - 63\n",
      "alignment: 55 - 64\n",
      "alignment: 56 - 65\n",
      "alignment: 57 - 66\n",
      "alignment: 58 - 67\n",
      "alignment: 59 - 68\n",
      "alignment: 60 - 69\n",
      "alignment: 61 - 70\n",
      "alignment: 62 - 71\n",
      "alignment: 63 - 72\n",
      "alignment: 64 - 73,74\n",
      "alignment: 65 - 75\n",
      "alignment: 66 - 76\n",
      "alignment: 67 - 77\n",
      "alignment: 68 - 78\n",
      "alignment: 69 - 79,80\n",
      "alignment: 70 - 81\n",
      "alignment: 71 - 82\n",
      "alignment: 72 - 83\n",
      "alignment: 73 - 84,85\n",
      "alignment: 74 - 86\n",
      "alignment: 75 - 87\n",
      "alignment: 76 - 88\n",
      "alignment: 77 - 89\n",
      "alignment: 78 - 90\n",
      "alignment: 79 - 91\n",
      "alignment: 80 - 93,94\n",
      "alignment: 81 - 95,96\n",
      "alignment: 82 - 97,98,99\n",
      "alignment: 83 - 100\n",
      "alignment: 84 - 101\n",
      "alignment: 85 - 102,103\n",
      "alignment: 86 - 104\n",
      "alignment: 87 - 106\n",
      "alignment: 88 - 107\n",
      "alignment: 89 - 108\n",
      "alignment: 90 - 109\n",
      "alignment: 91 - 110\n",
      "alignment: 92 - 111\n",
      "alignment: 93 - 112\n",
      "alignment: 94 - 113\n",
      "alignment: 95 - 114\n",
      "alignment: 96 - 115\n",
      "alignment: 97 - 116\n",
      "alignment: 98 - 117\n",
      "alignment: 99 - 118,119\n",
      "alignment: 100 - 120\n",
      "alignment: 101 - 121\n",
      "alignment: 102 - 123\n",
      "alignment: 103 - 124\n",
      "alignment: 104 - 125\n",
      "alignment: 105 - 126\n",
      "alignment: 106 - 127\n",
      "alignment: 107 - 128\n",
      "alignment: 108 - 129\n",
      "alignment: 109 - 130,131\n",
      "alignment: 110 - 132\n",
      "alignment: 111 - 133\n",
      "alignment: 112 - 134\n",
      "alignment: 113 - 135,136\n",
      "alignment: 114 - 138\n",
      "alignment: 115 - 139\n",
      "alignment: 116 - 140\n",
      "alignment: 117 - 141\n",
      "alignment: 118,119 - 142\n",
      "alignment: 120 - 144\n",
      "alignment: 121 - 145\n",
      "alignment: 122 - 146\n",
      "alignment: 123 - 147\n",
      "alignment: 124 - 148\n",
      "alignment: 125 - 149\n",
      "alignment: 126 - 150\n",
      "alignment: 127 - 152,153\n",
      "alignment: 128 - 154\n",
      "alignment: 130 - 155,156\n",
      "alignment: 131 - 158\n",
      "alignment: 132 - 159\n",
      "alignment: 133 - 160\n",
      "alignment: 134,135 - 161\n",
      "alignment: 136 - 163\n",
      "alignment: 137 - 164,165\n",
      "alignment: 138 - 166,167,168\n",
      "alignment: 139 - 169\n",
      "alignment: 140,141 - 170\n",
      "alignment: 145 - 171,172\n",
      "alignment: 146 - 174\n",
      "alignment: 147 - 175\n",
      "alignment: 148 - 176\n",
      "alignment: 149 - 177\n",
      "alignment: 150 - 178\n",
      "alignment: 151 - 179\n",
      "alignment: 152 - 180\n",
      "alignment: 153 - 181\n",
      "alignment: 154 - 182\n",
      "alignment: 155 - 183\n",
      "alignment: 156 - 184\n",
      "alignment: 157 - 185\n",
      "alignment: 158 - 186,187\n",
      "alignment: 159 - 188\n",
      "alignment: 160 - 189,190\n",
      "alignment: 161 - 191\n",
      "alignment: 162 - 192\n",
      "alignment: 163 - 193,194\n",
      "alignment: 164 - 196,197\n",
      "alignment: 165 - 198\n",
      "alignment: 166 - 199,200\n",
      "alignment: 167 - 201\n",
      "alignment: 168 - 202\n",
      "alignment: 169 - 203\n",
      "alignment: 171 - 208\n",
      "alignment: 172 - 209,210\n",
      "alignment: 173 - 211\n",
      "alignment: 174 - 212\n",
      "alignment: 175 - 213\n",
      "alignment: 176 - 214\n",
      "alignment: 177 - 215\n",
      "alignment: 178 - 216,217\n",
      "alignment: 179 - 218\n",
      "alignment: 180 - 219\n",
      "alignment: 181 - 220\n",
      "alignment: 182 - 221\n",
      "alignment: 183 - 222\n",
      "alignment: 184 - 223\n",
      "alignment: 185 - 224\n",
      "alignment: 186 - 226\n",
      "alignment: 187 - 227\n",
      "alignment: 188 - 228,229\n",
      "alignment: 189 - 231\n",
      "alignment: 190 - 232\n",
      "alignment: 191 - 233,234\n",
      "alignment: 192 - 236,237\n",
      "alignment: 193 - 238\n",
      "alignment: 194 - 239\n",
      "alignment: 195 - 240\n",
      "alignment: 196 - 241,242\n",
      "alignment: 197 - 243,244,245\n",
      "alignment: 198 - 248,249\n",
      "alignment: 199 - 249\n",
      "alignment: 200,201 - 250\n",
      "alignment: 202 - 251\n",
      "alignment: 203 - 252\n",
      "alignment: 204 - 253\n",
      "alignment: 205 - 254\n",
      "alignment: 206 - 255\n",
      "alignment: 207 - 256,257\n",
      "alignment: 208 - 258\n",
      "alignment: 209,210 - 260,261\n",
      "alignment: 211 - 262\n",
      "alignment: 212 - 263\n",
      "alignment: 213 - 264\n",
      "alignment: 214 - 265\n",
      "alignment: 215 - 266\n",
      "alignment: 216 - 267\n",
      "alignment: 217 - 268,269\n",
      "alignment: 218 - 270,271\n",
      "alignment: 219,220 - 273\n",
      "alignment: 221 - 274\n",
      "alignment: 222 - 276\n",
      "alignment: 223,224 - 277\n",
      "alignment: 225 - 279\n",
      "\n",
      "finished with article\n",
      "\n",
      "====================\n",
      "\n",
      "sentence alignment took 1.2122130393981934 seconds\n"
     ]
    }
   ],
   "source": [
    "# %%capture cap --no-stderr\n",
    "start = time.time()\n",
    "!./bleualign.py -s texts/spanish/sourcetextforbleualign.txt -t texts/spanish/targettextforbleualign.txt --srctotarget texts/spanish/translatedsource.txt -o texts/spanish/outputfile --verbosity 2\n",
    "end = time.time()\n",
    "print(f'sentence alignment took {end-start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [START HERE] 3. Read sentence-aligned files (from Bleualign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'texts/{srclang}/outputfile-s','r') as f:\n",
    "    alignedsrc = f.read().split('\\n')\n",
    "with open(f'texts/{srclang}/outputfile-t','r') as f:\n",
    "    alignedtgt = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Si mi boca, antes que la deshiciera un balazo, pudiera gritar ese nombre de modo que lo oyeran en Alemania... Mi voz humana era muy pobre.',\n",
       " 'If only my mouth, before it should be silenced by a bullet, could shout this name in such a way that it could be heard in Germany . . . My voice, my human voice, was weak.')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = random.choice(range(len(alignedsrc)))\n",
    "alignedsrc[i], alignedtgt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/226 sentences parsed.\n",
      "50/226 sentences parsed.\n",
      "100/226 sentences parsed.\n",
      "150/226 sentences parsed.\n",
      "200/226 sentences parsed.\n"
     ]
    }
   ],
   "source": [
    "# sent to sent alignment\n",
    "oneLineSpa, oneLineEng = rawsrcsents, rawtgtsents\n",
    "alignedSpa, alignedEng = alignedsrc, alignedtgt\n",
    "sentAlignments = []\n",
    "alignmentLookup = dict()\n",
    "spaIndex = 0\n",
    "for alignSpaSent, alignEngSent in zip(alignedSpa, alignedEng):\n",
    "    if spaIndex % 50 == 0:\n",
    "        print(f'{spaIndex}/{len(rawsrcsents)} sentences parsed.')\n",
    "    individualEngSents = [sent.text for sent in engNLP(alignEngSent).sents]\n",
    "    for indEngSent in individualEngSents:\n",
    "        for i, thisEngLine in enumerate(oneLineEng):\n",
    "            if indEngSent.strip() == thisEngLine.strip():\n",
    "                engIndex = i\n",
    "        for j, thisSpaLine in enumerate(oneLineSpa):\n",
    "            if alignSpaSent.strip() == thisSpaLine.strip():\n",
    "                spaIndex = j\n",
    "        sentAlignments.append({\n",
    "            'indices' : (spaIndex, engIndex),\n",
    "            'sents' : (oneLineSpa[spaIndex], oneLineEng[engIndex])\n",
    "        })\n",
    "        alignmentLookup.setdefault(spaIndex,[])\n",
    "        alignmentLookup[spaIndex].append(engIndex)\n",
    "    spaIndex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'jsondata/{srclang}/sentAlignment4-8.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sentAlignments, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE DONT NEED - check it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esa trama de tiempos que se aproximan, se bifurcan, se cortan o que secularmente se ignoran, abarca todas las posibilidades.\n",
      "He believed in an infinite series of times, in a dizzily growing, ever spreading network of diverging, converging and parallel times.\n"
     ]
    }
   ],
   "source": [
    "# chec, k it works\n",
    "randSentAlign = random.choice(sentAlignments)\n",
    "s, t = randSentAlign['sents']\n",
    "print(s)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Parse word alignment using SimAlign (recommended: fast and high coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install simalign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2022-04-07 18:27:56,278 - simalign.simalign - INFO - Initialized the EmbeddingLoader with model: bert-base-multilingual-cased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading word aligner tool took 24.096473217010498 seconds\n"
     ]
    }
   ],
   "source": [
    "from simalign import SentenceAligner\n",
    "start = time.time()\n",
    "# making an instance of our model.\n",
    "# You can specify the embedding model and all alignment settings in the constructor.\n",
    "myaligner = SentenceAligner(model=\"bert\", token_type=\"bpe\", matching_methods=\"mai\")\n",
    "end = time.time()\n",
    "print(f'downloading word aligner tool took {end-start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate word alignment with SimAlign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rawsrcsents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/226 sentences parsed in 0.0003972053527832031 s.\n",
      "25/226 sentences parsed in 30.3469979763031 s.\n",
      "50/226 sentences parsed in 55.82429313659668 s.\n",
      "75/226 sentences parsed in 77.6922881603241 s.\n",
      "100/226 sentences parsed in 109.99845719337463 s.\n",
      "125/226 sentences parsed in 123.02643013000488 s.\n",
      "150/226 sentences parsed in 135.3704390525818 s.\n",
      "175/226 sentences parsed in 158.83312106132507 s.\n",
      "200/226 sentences parsed in 179.96948099136353 s.\n",
      "225/226 sentences parsed in 190.1589879989624 s.\n",
      "parsed in 190.40406203269958 s\n"
     ]
    }
   ],
   "source": [
    "# get rid of white space at end\n",
    "your_data = zip(rawsrcsents, rawtgtsents)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "wordAlignmentList = []\n",
    "\n",
    "for i, srcsent in enumerate(rawsrcsents):\n",
    "    if i % 25 == 0:\n",
    "        currently = time.time()\n",
    "        print(f\"{i}/{len(rawsrcsents)} sentences parsed in {currently-start} s.\")\n",
    "\n",
    "    srcDoc = sourceNLP(srcsent)\n",
    "    \n",
    "    srcTokens = []\n",
    "    for token in srcDoc:\n",
    "        srcTokens.append({\n",
    "            'tokenid' : token.idx,\n",
    "            'pos' : token.pos_, \n",
    "            'text' : token.text, \n",
    "            'lemma' : token.lemma_,\n",
    "            'features' : Morphology.feats_to_dict(str(token.morph))\n",
    "        })\n",
    "\n",
    "    try:\n",
    "        jLst = alignmentLookup[i]\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    for j in jLst:\n",
    "        tgtDoc = engNLP(rawtgtsents[j])\n",
    "\n",
    "        tgtTokens = []\n",
    "        for token in tgtDoc:\n",
    "            tgtTokens.append({\n",
    "                'tokenid' : token.idx,\n",
    "                'pos' : token.pos_, \n",
    "                'text' : token.text, \n",
    "                'lemma' : token.lemma_,\n",
    "                'features' : Morphology.feats_to_dict(str(token.morph))\n",
    "            })\n",
    "\n",
    "        src = [t.text for t in srcDoc]\n",
    "        tgt = [t.text for t in tgtDoc]\n",
    "\n",
    "        alignments = myaligner.get_word_aligns(src, tgt)\n",
    "        itermax = alignments['itermax']\n",
    "\n",
    "        wordAlignmentList.append({\n",
    "            'alignedwordindices' : itermax,\n",
    "            'alignedwords' : [(src[s], tgt[t]) for s, t in itermax],\n",
    "            'srctokens' : srcTokens,\n",
    "            'tgttokens' : tgtTokens,\n",
    "            'srcsentidx' : i,\n",
    "            'tgtsentidx' : j,\n",
    "        })\n",
    "end = time.time()\n",
    "print('parsed in',end-start,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to JSON or CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'jsondata/{srclang}/wordAlignment4-8.json', 'w',encoding='utf-8') as f:\n",
    "    json.dump(wordAlignmentList, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "')'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srcsent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "srctokens = []\n",
    "tgttokens = []\n",
    "for srcsent in rawsrcsents:\n",
    "    srcdoc = sourceNLP(srcsent)\n",
    "    senttokens = [{\n",
    "            'tokenid' : token.idx,\n",
    "            'pos' : token.pos_, \n",
    "            'text' : token.text, \n",
    "            'lemma' : token.lemma_,\n",
    "            'features' : Morphology.feats_to_dict(str(token.morph)),\n",
    "            'linebreak' : False\n",
    "        } for token in srcdoc]\n",
    "    srctokens.append({\n",
    "        'text' : srcsent,\n",
    "        'tokens' : senttokens\n",
    "    })\n",
    "for tgtsent in rawtgtsents:\n",
    "    tgtdoc = engNLP(tgtsent)\n",
    "    senttokens = [{\n",
    "            'tokenid' : token.idx,\n",
    "            'pos' : token.pos_, \n",
    "            'text' : token.text, \n",
    "            'lemma' : token.lemma_,\n",
    "            'features' : Morphology.feats_to_dict(str(token.morph)),\n",
    "            'linebreak' : False\n",
    "        } for token in tgtdoc]\n",
    "    tgttokens.append({\n",
    "        'text' : tgtsent,\n",
    "        'tokens' : senttokens\n",
    "    })\n",
    "\n",
    "sentsInOrderJSON = {'srcSentsInOrder' : srctokens, 'tgtSentsInOrder' : tgttokens}\n",
    "with open(f'jsondata/{srclang}/sentsInOrder4-8.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sentsInOrderJSON, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
