{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load aligment list as python list\n",
    "with open('alignment2-26.pickle', 'rb') as handle:\n",
    "    alignmentList = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spanishRawText': 'Lo hice, porque yo sentía que el jefe temía un poco a los de mi raza -a los innumerables antepasados que confluyen en mí-.',\n",
       " 'englishRawText': 'I carried out my plan because I felt the Chief had some fear of those of my race, of those uncountable forebears whose culmination lies in me.',\n",
       " 'spanishTokenList': [{'tokenid': 0,\n",
       "   'POS': None,\n",
       "   'text': '[[NULL]]',\n",
       "   'lemma': None,\n",
       "   'features': None},\n",
       "  {'tokenid': 1,\n",
       "   'POS': 'PRON',\n",
       "   'text': 'Lo',\n",
       "   'lemma': 'él',\n",
       "   'features': 'Case=Acc|Gender=Masc|Number=Sing|Person=3|PrepCase=Npr|PronType=Prs'},\n",
       "  {'tokenid': 2,\n",
       "   'POS': 'VERB',\n",
       "   'text': 'hice',\n",
       "   'lemma': 'hacer',\n",
       "   'features': 'Mood=Ind|Number=Sing|Person=1|Tense=Past|VerbForm=Fin'},\n",
       "  {'tokenid': 3,\n",
       "   'POS': 'PUNCT',\n",
       "   'text': ',',\n",
       "   'lemma': ',',\n",
       "   'features': 'PunctType=Comm'},\n",
       "  {'tokenid': 4,\n",
       "   'POS': 'SCONJ',\n",
       "   'text': 'porque',\n",
       "   'lemma': 'porque',\n",
       "   'features': '_'},\n",
       "  {'tokenid': 5,\n",
       "   'POS': 'PRON',\n",
       "   'text': 'yo',\n",
       "   'lemma': 'yo',\n",
       "   'features': 'Case=Nom|Number=Sing|Person=1|PronType=Prs'},\n",
       "  {'tokenid': 6,\n",
       "   'POS': 'VERB',\n",
       "   'text': 'sentía',\n",
       "   'lemma': 'sentir',\n",
       "   'features': 'Mood=Ind|Number=Sing|Person=3|Tense=Imp|VerbForm=Fin'},\n",
       "  {'tokenid': 7,\n",
       "   'POS': 'SCONJ',\n",
       "   'text': 'que',\n",
       "   'lemma': 'que',\n",
       "   'features': '_'},\n",
       "  {'tokenid': 8,\n",
       "   'POS': 'DET',\n",
       "   'text': 'el',\n",
       "   'lemma': 'el',\n",
       "   'features': 'Definite=Def|Gender=Masc|Number=Sing|PronType=Art'},\n",
       "  {'tokenid': 9,\n",
       "   'POS': 'NOUN',\n",
       "   'text': 'jefe',\n",
       "   'lemma': 'jefe',\n",
       "   'features': 'Gender=Masc|Number=Sing'},\n",
       "  {'tokenid': 10,\n",
       "   'POS': 'VERB',\n",
       "   'text': 'temía',\n",
       "   'lemma': 'temer',\n",
       "   'features': 'Mood=Ind|Number=Sing|Person=3|Tense=Imp|VerbForm=Fin'},\n",
       "  {'tokenid': 11,\n",
       "   'POS': 'DET',\n",
       "   'text': 'un',\n",
       "   'lemma': 'uno',\n",
       "   'features': 'Definite=Ind|Gender=Masc|Number=Sing|PronType=Art'},\n",
       "  {'tokenid': 12,\n",
       "   'POS': 'ADV',\n",
       "   'text': 'poco',\n",
       "   'lemma': 'poco',\n",
       "   'features': '_'},\n",
       "  {'tokenid': 13, 'POS': 'ADP', 'text': 'a', 'lemma': 'a', 'features': '_'},\n",
       "  {'tokenid': 14,\n",
       "   'POS': 'DET',\n",
       "   'text': 'los',\n",
       "   'lemma': 'el',\n",
       "   'features': 'Definite=Def|Gender=Masc|Number=Plur|PronType=Art'},\n",
       "  {'tokenid': 15, 'POS': 'ADP', 'text': 'de', 'lemma': 'de', 'features': '_'},\n",
       "  {'tokenid': 16,\n",
       "   'POS': 'DET',\n",
       "   'text': 'mi',\n",
       "   'lemma': 'mi',\n",
       "   'features': 'Number=Sing|Number[psor]=Sing|Person=1|Poss=Yes|PronType=Prs'},\n",
       "  {'tokenid': 17,\n",
       "   'POS': 'NOUN',\n",
       "   'text': 'raza',\n",
       "   'lemma': 'raza',\n",
       "   'features': 'Gender=Fem|Number=Sing'},\n",
       "  {'tokenid': 18,\n",
       "   'POS': 'PUNCT',\n",
       "   'text': '-',\n",
       "   'lemma': '-',\n",
       "   'features': 'PunctType=Dash'},\n",
       "  {'tokenid': 19, 'POS': 'ADP', 'text': 'a', 'lemma': 'a', 'features': '_'},\n",
       "  {'tokenid': 20,\n",
       "   'POS': 'DET',\n",
       "   'text': 'los',\n",
       "   'lemma': 'el',\n",
       "   'features': 'Definite=Def|Gender=Masc|Number=Plur|PronType=Art'},\n",
       "  {'tokenid': 21,\n",
       "   'POS': 'ADJ',\n",
       "   'text': 'innumerables',\n",
       "   'lemma': 'innumerable',\n",
       "   'features': 'Number=Plur'},\n",
       "  {'tokenid': 22,\n",
       "   'POS': 'NOUN',\n",
       "   'text': 'antepasados',\n",
       "   'lemma': 'antepasado',\n",
       "   'features': 'Gender=Masc|Number=Plur'},\n",
       "  {'tokenid': 23,\n",
       "   'POS': 'PRON',\n",
       "   'text': 'que',\n",
       "   'lemma': 'que',\n",
       "   'features': 'PronType=Int,Rel'},\n",
       "  {'tokenid': 24,\n",
       "   'POS': 'VERB',\n",
       "   'text': 'confluyen',\n",
       "   'lemma': 'confluir',\n",
       "   'features': 'Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin'},\n",
       "  {'tokenid': 25, 'POS': 'ADP', 'text': 'en', 'lemma': 'en', 'features': '_'},\n",
       "  {'tokenid': 26,\n",
       "   'POS': 'PRON',\n",
       "   'text': 'mí-',\n",
       "   'lemma': 'mí-',\n",
       "   'features': 'Number=Sing|Person=1|PronType=Prs'},\n",
       "  {'tokenid': 27,\n",
       "   'POS': 'PUNCT',\n",
       "   'text': '.',\n",
       "   'lemma': '.',\n",
       "   'features': 'PunctType=Peri'}],\n",
       " 'englishTokenList': [{'tokenid': 0,\n",
       "   'POS': None,\n",
       "   'text': '[[NULL]]',\n",
       "   'lemma': None,\n",
       "   'features': None},\n",
       "  {'tokenid': 1,\n",
       "   'POS': 'PRON',\n",
       "   'text': 'I',\n",
       "   'lemma': 'I',\n",
       "   'features': 'Case=Nom|Number=Sing|Person=1|PronType=Prs'},\n",
       "  {'tokenid': 2,\n",
       "   'POS': 'VERB',\n",
       "   'text': 'carried',\n",
       "   'lemma': 'carry',\n",
       "   'features': 'Mood=Ind|Tense=Past|VerbForm=Fin'},\n",
       "  {'tokenid': 3, 'POS': 'ADP', 'text': 'out', 'lemma': 'out', 'features': '_'},\n",
       "  {'tokenid': 4,\n",
       "   'POS': 'PRON',\n",
       "   'text': 'my',\n",
       "   'lemma': 'my',\n",
       "   'features': 'Number=Sing|Person=1|Poss=Yes|PronType=Prs'},\n",
       "  {'tokenid': 5,\n",
       "   'POS': 'NOUN',\n",
       "   'text': 'plan',\n",
       "   'lemma': 'plan',\n",
       "   'features': 'Number=Sing'},\n",
       "  {'tokenid': 6,\n",
       "   'POS': 'SCONJ',\n",
       "   'text': 'because',\n",
       "   'lemma': 'because',\n",
       "   'features': '_'},\n",
       "  {'tokenid': 7,\n",
       "   'POS': 'PRON',\n",
       "   'text': 'I',\n",
       "   'lemma': 'I',\n",
       "   'features': 'Case=Nom|Number=Sing|Person=1|PronType=Prs'},\n",
       "  {'tokenid': 8,\n",
       "   'POS': 'VERB',\n",
       "   'text': 'felt',\n",
       "   'lemma': 'feel',\n",
       "   'features': 'Mood=Ind|Tense=Past|VerbForm=Fin'},\n",
       "  {'tokenid': 9,\n",
       "   'POS': 'DET',\n",
       "   'text': 'the',\n",
       "   'lemma': 'the',\n",
       "   'features': 'Definite=Def|PronType=Art'},\n",
       "  {'tokenid': 10,\n",
       "   'POS': 'PROPN',\n",
       "   'text': 'Chief',\n",
       "   'lemma': 'Chief',\n",
       "   'features': 'Number=Sing'},\n",
       "  {'tokenid': 11,\n",
       "   'POS': 'VERB',\n",
       "   'text': 'had',\n",
       "   'lemma': 'have',\n",
       "   'features': 'Mood=Ind|Tense=Past|VerbForm=Fin'},\n",
       "  {'tokenid': 12,\n",
       "   'POS': 'DET',\n",
       "   'text': 'some',\n",
       "   'lemma': 'some',\n",
       "   'features': '_'},\n",
       "  {'tokenid': 13,\n",
       "   'POS': 'NOUN',\n",
       "   'text': 'fear',\n",
       "   'lemma': 'fear',\n",
       "   'features': 'Number=Sing'},\n",
       "  {'tokenid': 14, 'POS': 'ADP', 'text': 'of', 'lemma': 'of', 'features': '_'},\n",
       "  {'tokenid': 15,\n",
       "   'POS': 'PRON',\n",
       "   'text': 'those',\n",
       "   'lemma': 'that',\n",
       "   'features': 'Number=Plur|PronType=Dem'},\n",
       "  {'tokenid': 16, 'POS': 'ADP', 'text': 'of', 'lemma': 'of', 'features': '_'},\n",
       "  {'tokenid': 17,\n",
       "   'POS': 'PRON',\n",
       "   'text': 'my',\n",
       "   'lemma': 'my',\n",
       "   'features': 'Number=Sing|Person=1|Poss=Yes|PronType=Prs'},\n",
       "  {'tokenid': 18,\n",
       "   'POS': 'NOUN',\n",
       "   'text': 'race',\n",
       "   'lemma': 'race',\n",
       "   'features': 'Number=Sing'},\n",
       "  {'tokenid': 19, 'POS': 'PUNCT', 'text': ',', 'lemma': ',', 'features': '_'},\n",
       "  {'tokenid': 20, 'POS': 'ADP', 'text': 'of', 'lemma': 'of', 'features': '_'},\n",
       "  {'tokenid': 21,\n",
       "   'POS': 'DET',\n",
       "   'text': 'those',\n",
       "   'lemma': 'that',\n",
       "   'features': 'Number=Plur|PronType=Dem'},\n",
       "  {'tokenid': 22,\n",
       "   'POS': 'ADJ',\n",
       "   'text': 'uncountable',\n",
       "   'lemma': 'uncountable',\n",
       "   'features': 'Degree=Pos'},\n",
       "  {'tokenid': 23,\n",
       "   'POS': 'NOUN',\n",
       "   'text': 'forebears',\n",
       "   'lemma': 'forebear',\n",
       "   'features': 'Number=Plur'},\n",
       "  {'tokenid': 24,\n",
       "   'POS': 'PRON',\n",
       "   'text': 'whose',\n",
       "   'lemma': 'whose',\n",
       "   'features': 'Poss=Yes|PronType=Int'},\n",
       "  {'tokenid': 25,\n",
       "   'POS': 'NOUN',\n",
       "   'text': 'culmination',\n",
       "   'lemma': 'culmination',\n",
       "   'features': 'Number=Sing'},\n",
       "  {'tokenid': 26,\n",
       "   'POS': 'VERB',\n",
       "   'text': 'lies',\n",
       "   'lemma': 'lie',\n",
       "   'features': 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin'},\n",
       "  {'tokenid': 27, 'POS': 'ADP', 'text': 'in', 'lemma': 'in', 'features': '_'},\n",
       "  {'tokenid': 28,\n",
       "   'POS': 'PRON',\n",
       "   'text': 'me',\n",
       "   'lemma': 'I',\n",
       "   'features': 'Case=Acc|Number=Sing|Person=1|PronType=Prs'},\n",
       "  {'tokenid': 29, 'POS': 'PUNCT', 'text': '.', 'lemma': '.', 'features': '_'}],\n",
       " 'alignmentTuples': [(0, 0),\n",
       "  (0, 1),\n",
       "  (0, 2),\n",
       "  (0, 4),\n",
       "  (0, 5),\n",
       "  (0, 13),\n",
       "  (1, 0),\n",
       "  (2, 3),\n",
       "  (3, 0),\n",
       "  (4, 6),\n",
       "  (5, 7),\n",
       "  (6, 8),\n",
       "  (6, 11),\n",
       "  (7, 0),\n",
       "  (8, 9),\n",
       "  (9, 10),\n",
       "  (10, 11),\n",
       "  (11, 12),\n",
       "  (12, 0),\n",
       "  (13, 14),\n",
       "  (14, 15),\n",
       "  (15, 16),\n",
       "  (16, 17),\n",
       "  (17, 18),\n",
       "  (18, 19),\n",
       "  (19, 20),\n",
       "  (20, 21),\n",
       "  (21, 22),\n",
       "  (22, 23),\n",
       "  (23, 24),\n",
       "  (24, 25),\n",
       "  (24, 26),\n",
       "  (25, 27),\n",
       "  (26, 28),\n",
       "  (27, 29)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alignmentList is a list of Python dictionaries with many attributes\n",
    "random.choice(alignmentList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[NULL]] \t\t[[NULL]]\n",
      "[[NULL]] \t\tan\n",
      "[[NULL]] \t\tto\n",
      "El \t\tThe\n",
      "casi \t\talmost\n",
      "intolerable \t\tunbearable\n",
      "recuerdo \t\tmemory\n",
      "de \t\tof\n",
      "el \t\t's\n",
      "rostro \t\tlong\n",
      "rostro \t\thorseface\n",
      "acaballado \t\t[[NULL]]\n",
      "de \t\t[[NULL]]\n",
      "Madden \t\tMadden\n",
      "abolió \t\tput\n",
      "abolió \t\tend\n",
      "esas \t\tthese\n",
      "divagaciones \t\twandering\n",
      "divagaciones \t\tthoughts\n",
      ". \t\t.\n"
     ]
    }
   ],
   "source": [
    "# see alignment tuples (words) for random list\n",
    "randSent = random.choice(alignmentList)\n",
    "for es,en in randSent['alignmentTuples']:\n",
    "    if randSent['alignmentTuples'] == []:\n",
    "        print('No alignment found')\n",
    "        break\n",
    "    print(randSent['spanishTokenList'][es]['text'], \n",
    "          '\\t\\t'+randSent['englishTokenList'][en]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
